# AI Voice Agent - Complete Feature Documentation

## üé§ Overview

A fully functional AI voice agent powered by **Azure Speech Services** and **Azure OpenAI (GPT-4)**. This is a production-ready implementation that showcases your Voice AI expertise from LiaPlus AI.

## üèóÔ∏è Architecture

```
User Voice Input
    ‚Üì
Azure Speech STT (Speech-to-Text)
    ‚Üì
Azure OpenAI GPT-4 (with Resume Context)
    ‚Üì
Intelligent Response + Command Execution
    ‚Üì
Azure Speech TTS (Text-to-Speech)
    ‚Üì
Natural Voice Output
```

## ‚ú® Features

### 1. Natural Conversations
- Ask about Amit's experience, skills, projects
- Get intelligent, context-aware responses
- Conversational tone optimized for voice

### 2. Automatic Command Execution
- AI can run terminal commands for you
- Say "Show me his skills" ‚Üí Agent runs `skills --graph`
- Say "Tell me about his experience" ‚Üí Agent can run `experience`

### 3. Multi-Modal Input
- **Voice**: Speak naturally to the AI
- **Text**: Type messages if you prefer
- Seamless switching between both modes

### 4. Smart Context
- Knows your entire resume
- Remembers conversation history
- Provides relevant suggestions

### 5. Professional Voice Output
- Neural TTS voices (Azure Speech)
- Natural prosody and intonation
- Configurable voice selection

## üìÅ Files Created

### API Routes
1. `app/api/voice-agent/llm/route.ts`
   - Handles GPT-4 conversations
   - Includes full resume context in system prompt
   - Parses command execution requests

2. `app/api/voice-agent/tts/route.ts`
   - Converts text to speech using Azure TTS
   - Returns base64-encoded MP3 audio
   - Optimized for conversational voice

### Components
3. `components/voice/VoiceAgent.tsx`
   - Full-screen modal UI for voice agent
   - Message display (conversation history)
   - Voice/text input controls
   - Real-time status indicators

### Hooks
4. `hooks/useVoiceAgent.ts`
   - Manages conversation state
   - Handles STT ‚Üí LLM ‚Üí TTS pipeline
   - Audio playback management
   - Command execution integration

### Commands
5. `commands/fun/fun.tsx`
   - Added `agent` command (aliases: `ai`, `assistant`, `aria`)
   - Terminal integration

### Documentation
6. `.env.example` - Environment variables template
7. `VOICE_AGENT_SETUP.md` - Complete setup guide

## üîß Setup Instructions

### 1. Install Dependencies (Already Done)
```bash
npm install microsoft-cognitiveservices-speech-sdk openai @azure/openai
```

### 2. Create `.env.local`
```bash
cp .env.example .env.local
```

### 3. Add Your API Keys

**Azure Speech Services:**
```
AZURE_SPEECH_KEY=your_key_here
AZURE_SPEECH_REGION=eastus
```

**Azure OpenAI:**
```
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your_key_here
AZURE_OPENAI_DEPLOYMENT=gpt-4
```

**Optional - Voice Configuration:**
```
VOICE_AGENT_NAME=Aria
VOICE_AGENT_VOICE=en-US-AriaNeural
```

### 4. Get API Keys

#### Azure Speech:
1. Go to https://portal.azure.com
2. Create "Speech Services" resource
3. Copy Key and Region

#### Azure OpenAI:
1. Go to https://portal.azure.com
2. Create "Azure OpenAI" resource
3. Deploy GPT-4 model
4. Copy Endpoint and API Key

## üéØ Usage

### Activate Voice Agent

In the terminal, type:
```bash
agent
```

Or use aliases:
```bash
ai
assistant
aria
```

### Example Conversations

**User:** "Tell me about Amit's experience"
**AI:** "Amit is currently a Software Engineer at LiaPlus AI, where he builds real-time Voice AI platforms with sub-500ms latency. Try the 'experience' command for more details!"

**User:** "What are his skills?"
**AI:** "Amit specializes in full-stack development with React, Next.js, Node.js, and Python. He's especially strong in Voice AI. Want to see a visual breakdown? EXECUTE_COMMAND: skills --graph"

**User:** "Show me his projects"
**AI:** "Let me show you! EXECUTE_COMMAND: projects"

## ü§ñ AI System Prompt

The agent is configured with:
- **Full resume knowledge** (experience, skills, education, projects, achievements)
- **Command awareness** (can execute terminal commands)
- **Conversational tone** (friendly, concise responses)
- **Context retention** (remembers conversation history)

Key behaviors:
- Keeps responses under 3 sentences for voice
- Suggests relevant commands
- Executes commands when asked
- Proud of Amit's work (especially Voice AI!)

## üé® UI/UX Features

### Status Indicators
- üé§ Listening (red, pulsing)
- ü§î Thinking (yellow)
- üîä Speaking (accent color)
- üí¨ Ready (green)

### Input Methods
- **Push-to-talk**: Click mic button
- **Continuous**: Auto-listens after agent speaks
- **Text input**: Type anytime

### Visual Design
- Full-screen modal overlay
- Message history with role indicators
- Smooth animations
- Theme-aware styling

## üìä Performance

### Latency Targets
- **STT**: <300ms (Azure Speech)
- **LLM**: ~1-2s (GPT-4)
- **TTS**: <500ms (Azure Speech)
- **Total**: <3s end-to-end

### Optimization
- Parallel API calls where possible
- Audio streaming (base64 MP3)
- Efficient state management
- Memoized components

## üí∞ Cost Estimation

**Azure Speech:**
- STT: $1 per hour of audio
- TTS: $15 per 1M characters

**Azure OpenAI (GPT-4):**
- Input: $0.03 per 1K tokens
- Output: $0.06 per 1K tokens

**Typical Usage:**
- 100 interactions ‚âà **$0.50 - $1.00**
- 1000 interactions ‚âà **$5.00 - $10.00**

## üîí Security

### API Keys
- Never commit `.env.local` (in `.gitignore`)
- Use environment variables in production
- Rotate keys regularly

### API Routes
- Server-side only (Next.js API routes)
- Keys never exposed to client
- Rate limiting recommended for production

## üöÄ Deployment

### Vercel (Recommended)
1. Push to GitHub
2. Connect to Vercel
3. Add environment variables in Vercel dashboard
4. Deploy!

### Environment Variables in Vercel
```
AZURE_SPEECH_KEY=your_key
AZURE_SPEECH_REGION=eastus
AZURE_OPENAI_ENDPOINT=https://...
AZURE_OPENAI_API_KEY=your_key
AZURE_OPENAI_DEPLOYMENT=gpt-4
VOICE_AGENT_NAME=Aria
VOICE_AGENT_VOICE=en-US-AriaNeural
```

## üé≠ Available Voices

**Female Voices:**
- `en-US-AriaNeural` (Friendly, default)
- `en-US-JennyNeural` (Assistant)
- `en-US-SaraNeural` (Professional)

**Male Voices:**
- `en-US-GuyNeural` (Professional)
- `en-US-DavisNeural` (Warm)
- `en-US-TonyNeural` (Authoritative)

Full list: https://learn.microsoft.com/azure/ai-services/speech-service/language-support

## üêõ Troubleshooting

### "Missing API keys" Error
- Verify `.env.local` exists
- Check all keys are correct
- Restart dev server: `npm run dev`

### No Audio Playback
- Check browser audio permissions
- Try different voice in settings
- Verify Azure Speech key

### LLM Not Responding
- Check Azure OpenAI endpoint URL
- Verify deployment name matches
- Check API key is valid

### Voice Recognition Not Working
- Use Chrome, Edge, or Safari
- Allow microphone permissions
- Check HTTPS in production

## üìà Analytics & Monitoring

### Recommended Tracking
- Conversation count
- Average response time
- Command execution frequency
- Error rates
- API usage costs

### Azure Portal Monitoring
- Speech API usage
- OpenAI token consumption
- Error logs
- Regional availability

## üéì Why This Is Impressive

### Technical Complexity
1. **Multi-service integration** (Speech STT + OpenAI + Speech TTS)
2. **Real-time audio processing**
3. **State management** (conversation history, audio queue)
4. **Context-aware AI** (full resume knowledge)
5. **Command execution** (AI ‚Üí Terminal integration)

### Voice AI Expertise
- Sub-3s latency (similar to production Voice AI systems)
- Natural conversation flow
- Multi-modal input handling
- Production-ready architecture

### Recruiter Impact
- **Directly showcases LiaPlus AI experience**
- Live demo of Voice AI skills
- Shows Azure proficiency
- Demonstrates full-stack capabilities

## üîÆ Future Enhancements

### Short-term
- [ ] Interrupt capability (stop agent mid-speech)
- [ ] Voice activity detection (VAD)
- [ ] Better error recovery
- [ ] Usage analytics

### Medium-term
- [ ] Multi-language support
- [ ] Voice cloning (your actual voice!)
- [ ] Persistent conversations (database)
- [ ] WebSocket for streaming

### Long-term
- [ ] Custom wake word ("Hey Aria!")
- [ ] Background mode (always listening)
- [ ] Integration with calendar/email
- [ ] RAG for deeper context

## üìö Resources

- [Azure Speech Docs](https://learn.microsoft.com/azure/ai-services/speech-service/)
- [Azure OpenAI Docs](https://learn.microsoft.com/azure/ai-services/openai/)
- [Next.js API Routes](https://nextjs.org/docs/app/building-your-application/routing/route-handlers)

---

## üéâ Summary

You now have a **production-ready AI voice agent** that:
- Uses Azure Speech STT + Azure OpenAI GPT-4 + Azure TTS
- Provides natural, intelligent conversations
- Executes terminal commands on request
- Works with voice AND text input
- Showcases your Voice AI expertise from LiaPlus AI

**Total commands now: 39** (was 38)

This is a **HUGE differentiator** for your portfolio! üöÄ
